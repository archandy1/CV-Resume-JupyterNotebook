{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcdb6f51-6804-477d-8426-af1da337c17d",
   "metadata": {},
   "source": [
    "### Installations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84b50aa-449d-41e6-903b-eb6046b93528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: langdetect in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\apleczkan\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pandas langdetect PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430f993a-2209-4021-a60f-2358e5a8a0b3",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54bdfb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langdetect import detect, DetectorFactory\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d88852-7c55-4dc6-a300-eb9d1947590e",
   "metadata": {},
   "source": [
    "### Set environment variable for Open Ai client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "809159d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53202e6b-24ea-418a-80e4-1b227e6cbc32",
   "metadata": {},
   "source": [
    "### Create basic Variables, paths and set Open AI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c847b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "directory_path = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\test_resumes_dataset\"\n",
    "translated_output_directory = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\resumes_translated\"\n",
    "max_chunk_size = 1000\n",
    "overlap_size = 50\n",
    "\n",
    "# Make langdetect non-deterministic results predictable\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "509d9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read PDF and extract text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae3dc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, max_chunk_size, overlap_size=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for word in words:\n",
    "        if len(current_chunk) + len(word) + 1 <= max_chunk_size:\n",
    "            current_chunk += word + \" \"\n",
    "        else:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = word + \" \"\n",
    "    chunks.append(current_chunk)  # Add the last chunk\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30c4be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate text using OpenAI's API (Updated for openai>=1.0.0)\n",
    "def translate_text(client, text, target_language=\"en\"):\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=f\"Translate the following text to {target_language}:\\n\\n{text}\",\n",
    "        max_tokens=500  # Adjust as needed\n",
    "    )\n",
    "    # Access the text from the response\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72a8e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_pdfs(directory_path, max_chunk_size, overlap_size, translated_output_directory, client):\n",
    "    if not os.path.exists(translated_output_directory):\n",
    "        os.makedirs(translated_output_directory)\n",
    "\n",
    "    translated_files_list = []\n",
    "    english_files_list = []\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(directory_path, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "            if text.strip():\n",
    "                if detect(text) != 'en':\n",
    "                    chunks = split_text(text, max_chunk_size, overlap_size)\n",
    "                    translated_text = \"\"\n",
    "\n",
    "                    for chunk in chunks:\n",
    "                        if detect(chunk) != 'en':\n",
    "                            chunk = translate_text(client, chunk, target_language=\"en\")\n",
    "                        translated_text += chunk + \" \"\n",
    "                    \n",
    "                    # Save the translated text to a .txt file\n",
    "                    translated_filename = f\"translated_{filename.replace('.pdf', '.txt')}\"\n",
    "                    translated_path = os.path.join(translated_output_directory, translated_filename)\n",
    "                    save_text_to_file(translated_text, translated_path)\n",
    "\n",
    "                    translated_files_list.append(translated_filename)\n",
    "                else:\n",
    "                    english_files_list.append(filename)\n",
    "            else:\n",
    "                print(f\"Document {filename} is empty or contains very little text.\")\n",
    "\n",
    "    # Save the list of translated files to a text file for reference\n",
    "    save_file_list(translated_files_list, translated_output_directory, 'translated_files_list.txt')\n",
    "    # Optionally save the list of English files as well\n",
    "    save_file_list(english_files_list, translated_output_directory, 'english_files_list.txt')\n",
    "\n",
    "def save_file_list(file_list, directory, filename):\n",
    "    with open(os.path.join(directory, filename), 'w', encoding='utf-8') as f:\n",
    "        for file in file_list:\n",
    "            f.write(f\"{file}\\n\")\n",
    "\n",
    "# Function to save text to a file\n",
    "def save_text_to_file(text, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21581aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 12632728.pdf is empty or contains very little text.\n"
     ]
    }
   ],
   "source": [
    "process_pdfs(directory_path, max_chunk_size, overlap_size, translated_output_directory, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4e8ef-b432-4801-80a7-db3b4c6ae79b",
   "metadata": {},
   "source": [
    "### Create named entities to look for in resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bd4ce8ea-f58f-444c-b133-d7ec08c5066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [\"job title\", \"years of experience\", \"highest level of education\", \"language skills\", \"key skills\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "53dfcd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "max_chunk_size = 3500  # Adjust as needed\n",
    "overlap_size = 50      # Adjust as needed\n",
    "\n",
    "\n",
    "def extract_text_from_txt(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'ISO-8859-1', 'cp1252']  # Common encodings\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as file:\n",
    "                return file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(f\"Cannot decode file {file_path} with any of the provided encodings.\")\n",
    "\n",
    "def split_into_chunks(text, max_chunk_size, overlap_size):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        if len(' '.join(current_chunk)) > max_chunk_size:\n",
    "            # Split the chunk at the max chunk size\n",
    "            chunk = ' '.join(current_chunk[:len(current_chunk)-overlap_size])\n",
    "            chunks.append(chunk)\n",
    "            # Start the next chunk with the overlap\n",
    "            current_chunk = current_chunk[-overlap_size:]\n",
    "    \n",
    "    # Add the last chunk\n",
    "    chunks.append(' '.join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "def extract_entities_with_llm(client, text, entities, max_chunk_size, overlap_size):\n",
    "    extracted_info = \"\"\n",
    "    chunks = split_into_chunks(text, max_chunk_size, overlap_size)  # Ensure chunks are small enough\n",
    "\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"Please extract the following entities from this text: {', '.join(entities)}.\\n\\n{chunk}\"\n",
    "        prompt_length = len(prompt.split())  # Calculate the prompt length in tokens\n",
    "\n",
    "        max_tokens_for_completion = 4097 - prompt_length  # Adjust max tokens based on prompt length\n",
    "        max_tokens_for_completion = min(max_tokens_for_completion, 300)  # Limit to 300 or less\n",
    "\n",
    "        response = client.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens_for_completion\n",
    "        )\n",
    "        extracted_info += response.choices[0].text.strip() + \"\\n\"\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "def process_resume(directory, filename, client, entities, data_list, is_txt=False):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    text = extract_text_from_txt(file_path) if is_txt else extract_text_from_pdf(file_path)\n",
    "    \n",
    "    if text.strip():\n",
    "        extracted_info = extract_entities_with_llm(client, text, entities, max_chunk_size, overlap_size)\n",
    "        info_dict = {'Filename': filename}\n",
    "        \n",
    "        for entity in entities:\n",
    "            # Use regex to find the entity and its value\n",
    "            pattern = re.compile(rf\"{entity}\\s*:\\s*(.*)\", re.IGNORECASE)\n",
    "            match = pattern.search(extracted_info)\n",
    "            if match:\n",
    "                info_dict[entity] = match.group(1).strip()\n",
    "            else:\n",
    "                info_dict[entity] = None  # Or an appropriate placeholder if not found\n",
    "        \n",
    "        data_list.append(info_dict)\n",
    "\n",
    "\n",
    "def create_entities_report(directory_path, translated_output_directory, client, entities):\n",
    "    data = []\n",
    "    # Process PDFs in the original directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            process_resume(directory_path, filename, client, entities, data)\n",
    "\n",
    "    # Process translated PDFs in the output directory\n",
    "    for filename in os.listdir(translated_output_directory):\n",
    "        if filename.lower().startswith('translated_') and filename.lower().endswith('.txt'):\n",
    "            process_resume(translated_output_directory, filename, client, entities, data, is_txt=True)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(os.path.join(translated_output_directory, 'resume_entities_report.xlsx'), index=False)\n",
    "\n",
    "create_entities_report(directory_path, translated_output_directory, client, entities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0ddd0-ae3c-456f-86fa-fc9a8ff45bca",
   "metadata": {},
   "source": [
    "### Data Frame from CV's for named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "055f38d7-f975-4993-a96f-0218caafd069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skills</th>\n",
       "      <th>experience_years</th>\n",
       "      <th>education_level</th>\n",
       "      <th>languages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10276858.pdf</th>\n",
       "      <td>Culinary insight, food preparation, kitchen pr...</td>\n",
       "      <td>5+ years in food and beverage experience</td>\n",
       "      <td>Not mentioned</td>\n",
       "      <td>Not mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329506.pdf</th>\n",
       "      <td>Dreamweaver, Adobe PageMaker 6.5, Adobe Photos...</td>\n",
       "      <td>19 (from 2001 to 2020)</td>\n",
       "      <td>B.S in Computer Information Systems from Stray...</td>\n",
       "      <td>None mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10344379.pdf</th>\n",
       "      <td>Strong organizational, technical, and interper...</td>\n",
       "      <td>3 years as a customer service advocate, 1 year...</td>\n",
       "      <td>None mentioned.</td>\n",
       "      <td>None mentioned.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395944.pdf</th>\n",
       "      <td>Customer service, leadership, team leadership,...</td>\n",
       "      <td>1 year as Line Service Technician, 6 months as...</td>\n",
       "      <td>Associate of Applied Science in Aviation Pilot...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10428916.pdf</th>\n",
       "      <td>ACSM Exercise Physiologist, TRX Qualified Inst...</td>\n",
       "      <td>9 years (Recreation &amp; Sports Coordinator: 6 ye...</td>\n",
       "      <td>Bachelor of Science in Kinesiology</td>\n",
       "      <td>None mentioned in text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10466583.pdf</th>\n",
       "      <td>customer service, inventory control, employee ...</td>\n",
       "      <td>June 2013 to March 2016, January 2011 to Decem...</td>\n",
       "      <td>Medical Assistant degree from Northwestern Col...</td>\n",
       "      <td>None mentioned in text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10527994.pdf</th>\n",
       "      <td>Outlook, Excel, Word, PowerPoint, QuickBooks, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10554236.pdf</th>\n",
       "      <td>financial planning, reporting and analysis, ac...</td>\n",
       "      <td>July 2011 to November 2012 (1 year, 5 months);...</td>\n",
       "      <td>Bachelor's degree in Accounting</td>\n",
       "      <td>None mentioned in the text.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603337.pdf</th>\n",
       "      <td>customer service, photo, credit, editing, fash...</td>\n",
       "      <td>5</td>\n",
       "      <td>Associates Degree and High School Diploma</td>\n",
       "      <td>None mentioned in the text.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10641230.pdf</th>\n",
       "      <td>Troubleshooting, Networking, Server Technologi...</td>\n",
       "      <td>8 years (July 2011 to present)</td>\n",
       "      <td>Associate of Science in Information Technology...</td>\n",
       "      <td>HTML, HTML5, XML, CSS, CSS3, JavaScript, TCP/IP.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         skills  \\\n",
       "Filename                                                          \n",
       "10276858.pdf  Culinary insight, food preparation, kitchen pr...   \n",
       "10329506.pdf  Dreamweaver, Adobe PageMaker 6.5, Adobe Photos...   \n",
       "10344379.pdf  Strong organizational, technical, and interper...   \n",
       "10395944.pdf  Customer service, leadership, team leadership,...   \n",
       "10428916.pdf  ACSM Exercise Physiologist, TRX Qualified Inst...   \n",
       "10466583.pdf  customer service, inventory control, employee ...   \n",
       "10527994.pdf  Outlook, Excel, Word, PowerPoint, QuickBooks, ...   \n",
       "10554236.pdf  financial planning, reporting and analysis, ac...   \n",
       "10603337.pdf  customer service, photo, credit, editing, fash...   \n",
       "10641230.pdf  Troubleshooting, Networking, Server Technologi...   \n",
       "\n",
       "                                               experience_years  \\\n",
       "Filename                                                          \n",
       "10276858.pdf           5+ years in food and beverage experience   \n",
       "10329506.pdf                             19 (from 2001 to 2020)   \n",
       "10344379.pdf  3 years as a customer service advocate, 1 year...   \n",
       "10395944.pdf  1 year as Line Service Technician, 6 months as...   \n",
       "10428916.pdf  9 years (Recreation & Sports Coordinator: 6 ye...   \n",
       "10466583.pdf  June 2013 to March 2016, January 2011 to Decem...   \n",
       "10527994.pdf                                                NaN   \n",
       "10554236.pdf  July 2011 to November 2012 (1 year, 5 months);...   \n",
       "10603337.pdf                                                  5   \n",
       "10641230.pdf                     8 years (July 2011 to present)   \n",
       "\n",
       "                                                education_level  \\\n",
       "Filename                                                          \n",
       "10276858.pdf                                      Not mentioned   \n",
       "10329506.pdf  B.S in Computer Information Systems from Stray...   \n",
       "10344379.pdf                                    None mentioned.   \n",
       "10395944.pdf  Associate of Applied Science in Aviation Pilot...   \n",
       "10428916.pdf                 Bachelor of Science in Kinesiology   \n",
       "10466583.pdf  Medical Assistant degree from Northwestern Col...   \n",
       "10527994.pdf                                                NaN   \n",
       "10554236.pdf                    Bachelor's degree in Accounting   \n",
       "10603337.pdf          Associates Degree and High School Diploma   \n",
       "10641230.pdf  Associate of Science in Information Technology...   \n",
       "\n",
       "                                                     languages  \n",
       "Filename                                                        \n",
       "10276858.pdf                                     Not mentioned  \n",
       "10329506.pdf                                    None mentioned  \n",
       "10344379.pdf                                   None mentioned.  \n",
       "10395944.pdf                                           English  \n",
       "10428916.pdf                            None mentioned in text  \n",
       "10466583.pdf                            None mentioned in text  \n",
       "10527994.pdf                                               NaN  \n",
       "10554236.pdf                       None mentioned in the text.  \n",
       "10603337.pdf                       None mentioned in the text.  \n",
       "10641230.pdf  HTML, HTML5, XML, CSS, CSS3, JavaScript, TCP/IP.  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.path.join(translated_output_directory, 'resume_entities_report.xlsx')\n",
    "df = pd.read_excel(file_path)\n",
    "df.set_index('Filename', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9767af4-962e-42ae-9959-9f1247e9c4ae",
   "metadata": {},
   "source": [
    "### CV Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "77ed5d4a-41db-4c0e-a476-93bd68c5a38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def summarize_text(client, text, max_chunk_size=3000, overlap_size=50):\n",
    "    \"\"\"\n",
    "    This function uses OpenAI's GPT-3 model to generate a summary of the resume text.\n",
    "    \"\"\"\n",
    "\n",
    "    chunks = split_text(text, max_chunk_size, overlap_size)\n",
    "    summary = \"\"\n",
    "\n",
    "    for chunk in chunks:\n",
    "        prompt = (\n",
    "            \"Please summarize the following resume into a short paragraph that includes \"\n",
    "            \"the job title, years of experience, highest level of education, language skills, \"\n",
    "            \"and key skills:\\n\\n\" + chunk  # Use the current chunk, not the entire text\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            response = client.completions.create(\n",
    "                model=\"gpt-3.5-turbo-instruct\",  # Use the latest available model\n",
    "                prompt=prompt,\n",
    "                max_tokens=150,  # Adjust as needed for the summary length\n",
    "                temperature=0.5\n",
    "            )\n",
    "            chunk_summary = response.choices[0].text.strip()\n",
    "            summary += chunk_summary + \"\\n\"  # Concatenate the summaries from different chunks\n",
    "        except Exception as e:\n",
    "            # Handle any exception that occurs\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "79098dd0-15f5-4462-8a72-94f805c1ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         skills  \\\n",
      "Filename                                                          \n",
      "10276858.pdf  Culinary insight, food preparation, kitchen pr...   \n",
      "10329506.pdf  Microsoft Word, Excel, Power Point, Access, Ad...   \n",
      "10344379.pdf  organizational, technical, interpersonal, lead...   \n",
      "10395944.pdf  Great People Skills, Microsoft Office, Airport...   \n",
      "10428916.pdf  Recreation coordination, staff management, bud...   \n",
      "\n",
      "                                               experience_years  \\\n",
      "Filename                                                          \n",
      "10276858.pdf  4 years (from 01/2014 to 05/2015 in the food s...   \n",
      "10329506.pdf  Registered Client Service Associate for 9 year...   \n",
      "10344379.pdf  Over 5 years (Jan 2015 to Current as a custome...   \n",
      "10395944.pdf  03/2017 to Current Line Service Technician Com...   \n",
      "10428916.pdf  Not mentioned explicitly, but can be inferred ...   \n",
      "\n",
      "                                                education_level  \\\n",
      "Filename                                                          \n",
      "10276858.pdf  High School Diploma in Culinary/Auto Body Cour...   \n",
      "10329506.pdf             No specific education level mentioned.   \n",
      "10344379.pdf  Not specified, but likely some level of techni...   \n",
      "10395944.pdf  2018 Associate of Applied Science : Aviation P...   \n",
      "10428916.pdf                 Bachelor of Science in Kinesiology   \n",
      "\n",
      "                                        languages  \\\n",
      "Filename                                            \n",
      "10276858.pdf           Not mentioned in the text.   \n",
      "10329506.pdf                                  NaN   \n",
      "10344379.pdf  No specific languages are mentioned   \n",
      "10395944.pdf          None mentioned in the text.   \n",
      "10428916.pdf           None mentioned in the text   \n",
      "\n",
      "                                                        Summary  \n",
      "Filename                                                         \n",
      "10276858.pdf  Experienced and highly skilled Food Prep Chef ...  \n",
      "10329506.pdf  Experienced Registered Client Service Associat...  \n",
      "10344379.pdf  Experienced administrative support professiona...  \n",
      "10395944.pdf  This individual is a Line Service Technician w...  \n",
      "10428916.pdf  The candidate is a highly qualified Recreation...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory paths\n",
    "directory_path = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\test_resumes_dataset\"\n",
    "translated_output_directory = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\resumes_translated\"\n",
    "xlsx_file_path = os.path.join(translated_output_directory, \"resume_entities_report.xlsx\")\n",
    "\n",
    "# Load the DataFrame from the Excel file\n",
    "df = pd.read_excel(xlsx_file_path)\n",
    "df.set_index('Filename', inplace=True)\n",
    "\n",
    "# Iterate over the DataFrame and summarize each resume\n",
    "for filename in df.index:\n",
    "    # Determine the correct file path\n",
    "    if filename.startswith('translated_'):\n",
    "        resume_path = os.path.join(translated_output_directory, filename)\n",
    "    else:\n",
    "        resume_path = os.path.join(directory_path, filename)\n",
    "\n",
    "    # Skip non-resume files like 'translated_files_list.txt'\n",
    "    if 'translated_files_list' in filename:\n",
    "        continue\n",
    "\n",
    "    # Check the file extension and read the content\n",
    "    if resume_path.lower().endswith('.pdf'):\n",
    "        try:\n",
    "            resume_text = extract_text_from_pdf(resume_path)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while reading PDF file: {e}\")\n",
    "            continue\n",
    "    elif resume_path.lower().endswith('.txt'):\n",
    "        try:\n",
    "            resume_text = extract_text_from_txt(resume_path)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while reading text file: {e}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"Unsupported file format for file: {resume_path}\")\n",
    "        continue\n",
    "\n",
    "    # Generate a summary for the resume (assuming summarize_text function is defined)\n",
    "    summary = summarize_text(client, resume_text)\n",
    "    df.at[filename, 'Summary'] = summary\n",
    "\n",
    "# Uncomment the below lines to see the DataFrame and save it\n",
    "print(df.head())\n",
    "df.to_excel(os.path.join(translated_output_directory, 'updated_resume_summaries.xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f70c7980-ffe4-425b-b026-02140755b0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skills</th>\n",
       "      <th>experience_years</th>\n",
       "      <th>education_level</th>\n",
       "      <th>languages</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10276858.pdf</th>\n",
       "      <td>Culinary insight, food preparation, kitchen pr...</td>\n",
       "      <td>4 years (from 01/2014 to 05/2015 in the food s...</td>\n",
       "      <td>High School Diploma in Culinary/Auto Body Cour...</td>\n",
       "      <td>Not mentioned in the text.</td>\n",
       "      <td>Experienced and highly skilled Food Prep Chef ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329506.pdf</th>\n",
       "      <td>Microsoft Word, Excel, Power Point, Access, Ad...</td>\n",
       "      <td>Registered Client Service Associate for 9 year...</td>\n",
       "      <td>No specific education level mentioned.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experienced Registered Client Service Associat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10344379.pdf</th>\n",
       "      <td>organizational, technical, interpersonal, lead...</td>\n",
       "      <td>Over 5 years (Jan 2015 to Current as a custome...</td>\n",
       "      <td>Not specified, but likely some level of techni...</td>\n",
       "      <td>No specific languages are mentioned</td>\n",
       "      <td>Experienced administrative support professiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395944.pdf</th>\n",
       "      <td>Great People Skills, Microsoft Office, Airport...</td>\n",
       "      <td>03/2017 to Current Line Service Technician Com...</td>\n",
       "      <td>2018 Associate of Applied Science : Aviation P...</td>\n",
       "      <td>None mentioned in the text.</td>\n",
       "      <td>This individual is a Line Service Technician w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10428916.pdf</th>\n",
       "      <td>Recreation coordination, staff management, bud...</td>\n",
       "      <td>Not mentioned explicitly, but can be inferred ...</td>\n",
       "      <td>Bachelor of Science in Kinesiology</td>\n",
       "      <td>None mentioned in the text</td>\n",
       "      <td>The candidate is a highly qualified Recreation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         skills  \\\n",
       "Filename                                                          \n",
       "10276858.pdf  Culinary insight, food preparation, kitchen pr...   \n",
       "10329506.pdf  Microsoft Word, Excel, Power Point, Access, Ad...   \n",
       "10344379.pdf  organizational, technical, interpersonal, lead...   \n",
       "10395944.pdf  Great People Skills, Microsoft Office, Airport...   \n",
       "10428916.pdf  Recreation coordination, staff management, bud...   \n",
       "\n",
       "                                               experience_years  \\\n",
       "Filename                                                          \n",
       "10276858.pdf  4 years (from 01/2014 to 05/2015 in the food s...   \n",
       "10329506.pdf  Registered Client Service Associate for 9 year...   \n",
       "10344379.pdf  Over 5 years (Jan 2015 to Current as a custome...   \n",
       "10395944.pdf  03/2017 to Current Line Service Technician Com...   \n",
       "10428916.pdf  Not mentioned explicitly, but can be inferred ...   \n",
       "\n",
       "                                                education_level  \\\n",
       "Filename                                                          \n",
       "10276858.pdf  High School Diploma in Culinary/Auto Body Cour...   \n",
       "10329506.pdf             No specific education level mentioned.   \n",
       "10344379.pdf  Not specified, but likely some level of techni...   \n",
       "10395944.pdf  2018 Associate of Applied Science : Aviation P...   \n",
       "10428916.pdf                 Bachelor of Science in Kinesiology   \n",
       "\n",
       "                                        languages  \\\n",
       "Filename                                            \n",
       "10276858.pdf           Not mentioned in the text.   \n",
       "10329506.pdf                                  NaN   \n",
       "10344379.pdf  No specific languages are mentioned   \n",
       "10395944.pdf          None mentioned in the text.   \n",
       "10428916.pdf           None mentioned in the text   \n",
       "\n",
       "                                                        Summary  \n",
       "Filename                                                         \n",
       "10276858.pdf  Experienced and highly skilled Food Prep Chef ...  \n",
       "10329506.pdf  Experienced Registered Client Service Associat...  \n",
       "10344379.pdf  Experienced administrative support professiona...  \n",
       "10395944.pdf  This individual is a Line Service Technician w...  \n",
       "10428916.pdf  The candidate is a highly qualified Recreation...  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe489854-05af-4012-ab60-43aa42ca201e",
   "metadata": {},
   "source": [
    "### Scoring criteria based on provided vacancy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52d4721-b9da-4130-a26b-54597cc23b95",
   "metadata": {},
   "source": [
    "### Job requirements from job description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "099c70af-8248-4c50-9f36-0a2b24928eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    'Job Title': 'Full Stack Developer',\n",
      "    'Experience Years': 'At least 2 years',\n",
      "    'Education Level': 'Bachelor's degree in Computer Science or related field',\n",
      "    'Languages': 'English',\n",
      "    'Skills': ['Node.js', 'React.js', 'GraphQL', 'Express', 'Kubernetes', 'SQL Server', 'PostgreSQL', 'Kafka', 'RabbitMQ', 'C#', 'SOLR', 'Python', 'Sound engineering practices']\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_description = \"\"\"\n",
    "FullStack(NodeJS, ReactJS), Online Genealogy Service\n",
    "Client\n",
    "The client is an international company that provides an online genealogy service that helps its clients understand their past and family history.\n",
    "\n",
    "Project overview\n",
    "The core programming language is JavaScript (ES2020), a website running on React.js and GraphQL and the back-end platform is based on Node.js (Express). Microservices running under Kubernetes. The project methodology is Scrum.\n",
    "\n",
    "Team\n",
    "There are a few Full Stack teams, up to 8 people each. Each team has a team lead and a product owner.\n",
    "\n",
    "Position overview\n",
    "We are looking for a specialist to join one of the teams (which is more Frontend oriented) is working on the further development of existing platforms. Regarding the work schedule, each employee should be available till 4 pm UK time.\n",
    "\n",
    "Technology stack\n",
    "JavaScript, React.js, GraphQL, Node.js (Express), Kubernetes.\n",
    " \n",
    "Requirements\n",
    "Development experience using a Node.js (Express) + React.js stack\n",
    "Experience with SQL Server\n",
    "Experience with PostgreSQL\n",
    "Knowledge of Kafka\n",
    "Knowledge of RabbitMQ\n",
    "Dev-level experience with K8s/Docker\n",
    "Knowledge of sound engineering practices like pair programming, upfront automated testing, continuous deployment, and trunk-based development\n",
    "Spoken English\n",
    "\n",
    "Nice to have\n",
    "Knowledge of Apollo engine, Kafka, Postgres\n",
    "Experience with microservices architecture development\n",
    "Experience with GraphQL\n",
    "Experience with RabbitMQ, SQL Server\n",
    "Experience in development with C#\n",
    "Experience with SOLR\n",
    "Software development experience in Python\n",
    "\"\"\"\n",
    "\n",
    "entities = [\"job title\", \"years of experience\", \"highest level of education\", \"language skills\", \"key skills\"]\n",
    "\n",
    "entity_categories = {\n",
    "    \"job title\": \"Job Title\",\n",
    "    \"years of experience\": \"Experience Years\",\n",
    "    \"highest level of education\": \"Education Level\",\n",
    "    \"language skills\": \"Languages\",\n",
    "    \"key skills\": \"Skills\"\n",
    "}\n",
    "\n",
    "prompt = (\n",
    "    \"Please structure the job requirements from the text into the following categories: \"\n",
    "    + \", \".join([entity_categories[entity] for entity in entities])\n",
    "    + \". Provide the response in a format that can be easily parsed into a dictionary.\\n\\n\"\n",
    "    + job_description\n",
    ")\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=300  # Adjust as needed\n",
    ")\n",
    "extracted_requirements = response.choices[0].text.strip()\n",
    "print(extracted_requirements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a90a8aaf-0195-4f0c-b0b6-6c85de4af5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    'Job Title': 'Full Stack Developer',\n",
      "    'Experience Years': 'At least 2 years',\n",
      "    'Education Level': 'Bachelor's degree in Computer Science or related field',\n",
      "    'Languages': 'English',\n",
      "    'Skills': ['Node.js', 'React.js', 'GraphQL', 'Express', 'Kubernetes', 'SQL Server', 'PostgreSQL', 'Kafka', 'RabbitMQ', 'C#', 'SOLR', 'Python', 'Sound engineering practices']\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(extracted_requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda67ef2-9846-400f-a4a0-135ae065c025",
   "metadata": {},
   "source": [
    "### Scoring function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5f340b21-bb2b-4dd5-a89d-83dfb808ad68",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[167], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Assuming directory_path and job_requirements are defined elsewhere\u001b[39;00m\n\u001b[0;32m     65\u001b[0m entities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob title\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myears of experience\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhighest level of education\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage skills\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey skills\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 67\u001b[0m scored_resumes_df \u001b[38;5;241m=\u001b[39m score_resumes(directory_path, job_requirements, entities)\n\u001b[0;32m     68\u001b[0m scored_resumes_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Sorting by score in descending order\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(scored_resumes_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "Cell \u001b[1;32mIn[167], line 47\u001b[0m, in \u001b[0;36mscore_resumes\u001b[1;34m(directory_path, job_requirements, entities)\u001b[0m\n\u001b[0;32m     45\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory_path, filename)\n\u001b[0;32m     46\u001b[0m text \u001b[38;5;241m=\u001b[39m extract_text_from_txt(file_path)  \u001b[38;5;66;03m# Assuming this function exists\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m extracted_info \u001b[38;5;241m=\u001b[39m extract_entities_with_llm(client, text, entities, max_chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3500\u001b[39m, overlap_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)  \u001b[38;5;66;03m# Assuming this function exists\u001b[39;00m\n\u001b[0;32m     48\u001b[0m info_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFilename\u001b[39m\u001b[38;5;124m'\u001b[39m: filename}\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m entities:\n",
      "Cell \u001b[1;32mIn[140], line 66\u001b[0m, in \u001b[0;36mextract_entities_with_llm\u001b[1;34m(client, text, entities, max_chunk_size, overlap_size)\u001b[0m\n\u001b[0;32m     63\u001b[0m     max_tokens_for_completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4097\u001b[39m \u001b[38;5;241m-\u001b[39m prompt_length  \u001b[38;5;66;03m# Adjust max tokens based on prompt length\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     max_tokens_for_completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_tokens_for_completion, \u001b[38;5;241m300\u001b[39m)  \u001b[38;5;66;03m# Limit to 300 or less\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     67\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     68\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m     69\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens_for_completion\n\u001b[0;32m     70\u001b[0m     )\n\u001b[0;32m     71\u001b[0m     extracted_info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extracted_info\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:271\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\resources\\completions.py:506\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    505\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Completion \u001b[38;5;241m|\u001b[39m Stream[Completion]:\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    508\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    509\u001b[0m             {\n\u001b[0;32m    510\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    511\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m    512\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_of,\n\u001b[0;32m    513\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mecho\u001b[39m\u001b[38;5;124m\"\u001b[39m: echo,\n\u001b[0;32m    514\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    515\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    516\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    517\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    518\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    519\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    520\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    521\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    522\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    523\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuffix\u001b[39m\u001b[38;5;124m\"\u001b[39m: suffix,\n\u001b[0;32m    524\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    525\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    526\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    527\u001b[0m             },\n\u001b[0;32m    528\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    529\u001b[0m         ),\n\u001b[0;32m    530\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    531\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    532\u001b[0m         ),\n\u001b[0;32m    533\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mCompletion,\n\u001b[0;32m    534\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    535\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[Completion],\n\u001b[0;32m    536\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1167\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1154\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1155\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1162\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1164\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1165\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1166\u001b[0m     )\n\u001b[1;32m-> 1167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:856\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    848\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    849\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    854\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    855\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    857\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    858\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    859\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    860\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    861\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    862\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:885\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    882\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 885\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    886\u001b[0m         request,\n\u001b[0;32m    887\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    889\u001b[0m     )\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    891\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:915\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    907\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    911\u001b[0m )\n\u001b[0;32m    913\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 915\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    916\u001b[0m     request,\n\u001b[0;32m    917\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    918\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    919\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    920\u001b[0m )\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:943\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    940\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    944\u001b[0m         request,\n\u001b[0;32m    945\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    946\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    947\u001b[0m     )\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:980\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    978\u001b[0m     hook(request)\n\u001b[1;32m--> 980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:1016\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1013\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1016\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1020\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py:231\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    218\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    219\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    220\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    229\u001b[0m )\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 231\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    236\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    237\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    238\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    239\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    240\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool_lock:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    106\u001b[0m     (\n\u001b[0;32m    107\u001b[0m         http_version,\n\u001b[0;32m    108\u001b[0m         status,\n\u001b[0;32m    109\u001b[0m         reason_phrase,\n\u001b[0;32m    110\u001b[0m         headers,\n\u001b[1;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    113\u001b[0m         http_version,\n\u001b[0;32m    114\u001b[0m         status,\n\u001b[0;32m    115\u001b[0m         reason_phrase,\n\u001b[0;32m    116\u001b[0m         headers,\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    120\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[0;32m    121\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     },\n\u001b[0;32m    128\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    173\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    214\u001b[0m     )\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def calculate_matching_score(resume_info, job_requirements):\n",
    "    score = 0\n",
    "    num_criteria = 4  # Four criteria: Skills, Experience, Education, Languages\n",
    "\n",
    "    # Scoring for skills\n",
    "    if 'skills' in resume_info and job_requirements.get('skills'):\n",
    "        if len(job_requirements['skills']) > 0:\n",
    "            matched_skills = sum(skill.lower() in resume_info['skills'].lower() for skill in job_requirements['skills'])\n",
    "            score += (matched_skills / len(job_requirements['skills'])) / num_criteria\n",
    "        else:\n",
    "            num_criteria -= 1\n",
    "\n",
    "    # Scoring for experience\n",
    "    if 'experience_years' in resume_info and resume_info['experience_years']:\n",
    "        try:\n",
    "            experience_years = int(resume_info['experience_years'])\n",
    "            score += (1 if experience_years >= job_requirements['experience_years'] else 0) / num_criteria\n",
    "        except ValueError:\n",
    "            # If conversion to int fails, handle appropriately (e.g., score 0 for this criterion)\n",
    "            pass\n",
    "\n",
    "    # Scoring for education\n",
    "    if 'education_level' in resume_info:\n",
    "        score += (1 if job_requirements['education_level'].lower() in resume_info['education_level'].lower() else 0) / num_criteria\n",
    "\n",
    "    # Scoring for languages\n",
    "    if 'languages' in resume_info:\n",
    "        score += (1 if any(lang.lower() in resume_info['languages'].lower() for lang in job_requirements['languages']) else 0) / num_criteria\n",
    "\n",
    "    # Adjust the total score if any criteria were not applicable\n",
    "    if num_criteria < 4:\n",
    "        score = score * (4 / num_criteria)\n",
    "\n",
    "    return score\n",
    "\n",
    "def score_resumes(directory_path, job_requirements, entities):\n",
    "    data = []\n",
    "    # Iterate over each resume in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith('.pdf') or filename.lower().endswith('.txt'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            text = extract_text_from_txt(file_path)  # Assuming this function exists\n",
    "            extracted_info = extract_entities_with_llm(client, text, entities, max_chunk_size=3500, overlap_size=50)  # Assuming this function exists\n",
    "            info_dict = {'Filename': filename}\n",
    "\n",
    "            for entity in entities:\n",
    "                pattern = re.compile(rf\"{entity}\\s*:\\s*(.*)\", re.IGNORECASE)\n",
    "                match = pattern.search(extracted_info)\n",
    "                if match:\n",
    "                    info_dict[entity] = match.group(1).strip()\n",
    "                else:\n",
    "                    info_dict[entity] = None\n",
    "\n",
    "            resume_score = calculate_matching_score(info_dict, job_requirements)\n",
    "            info_dict['Score'] = resume_score\n",
    "            data.append(info_dict)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Assuming directory_path and job_requirements are defined elsewhere\n",
    "entities = [\"job title\", \"years of experience\", \"highest level of education\", \"language skills\", \"key skills\"]\n",
    "\n",
    "scored_resumes_df = score_resumes(directory_path, job_requirements, entities)\n",
    "scored_resumes_df.sort_values(by='Score', ascending=False, inplace=True)  # Sorting by score in descending order\n",
    "print(scored_resumes_df.head(10))  # Display top 10 candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b5bf57ba-2672-4b59-8381-6de4ca920386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience_years</th>\n",
       "      <th>education_level</th>\n",
       "      <th>languages</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10898339.pdf</td>\n",
       "      <td>communication, multitasking, organization</td>\n",
       "      <td>5</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>English, Spanish, French</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12491898.pdf</td>\n",
       "      <td>HTML, PDF conversion, Qt, coding</td>\n",
       "      <td>12</td>\n",
       "      <td>Not mentioned in the text</td>\n",
       "      <td>Not mentioned in the text</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10428916.pdf</td>\n",
       "      <td>NLP, programming, data analysis</td>\n",
       "      <td>5</td>\n",
       "      <td>Masters</td>\n",
       "      <td>English, Spanish, French</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11409460.pdf</td>\n",
       "      <td>C++, Java, Python, SQL, HTML, CSS, JavaScript</td>\n",
       "      <td>8</td>\n",
       "      <td>Bachelor's degree in Computer Science or relat...</td>\n",
       "      <td>English, Spanish, French, Mandarin Chinese</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11257723.pdf</td>\n",
       "      <td>n\bÅ¯</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>english</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10816645.pdf</td>\n",
       "      <td>HTML, PDF, Qt, CreationDate, ExtGState, Stream</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None.</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10909720.pdf</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11555549.pdf</td>\n",
       "      <td>No specific skills are mentioned in this text.</td>\n",
       "      <td>No mention of experience years.</td>\n",
       "      <td>None mentioned.</td>\n",
       "      <td>None mentioned.</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11522068.pdf</td>\n",
       "      <td>language processing, computer programming, dat...</td>\n",
       "      <td>7 years</td>\n",
       "      <td>Master's degree in Computer Science</td>\n",
       "      <td>English, German, French, Spanish</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11360471.pdf</td>\n",
       "      <td>HTML, Qt, CSS, JavaScript, HTML to PDF conversion</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>None mentioned</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Filename                                             skills  \\\n",
       "15  10898339.pdf          communication, multitasking, organization   \n",
       "28  12491898.pdf                   HTML, PDF conversion, Qt, coding   \n",
       "4   10428916.pdf                    NLP, programming, data analysis   \n",
       "25  11409460.pdf      C++, Java, Python, SQL, HTML, CSS, JavaScript   \n",
       "22  11257723.pdf                                               n\bÅ¯   \n",
       "11  10816645.pdf     HTML, PDF, Qt, CreationDate, ExtGState, Stream   \n",
       "16  10909720.pdf                                            unknown   \n",
       "27  11555549.pdf     No specific skills are mentioned in this text.   \n",
       "26  11522068.pdf  language processing, computer programming, dat...   \n",
       "24  11360471.pdf  HTML, Qt, CSS, JavaScript, HTML to PDF conversion   \n",
       "\n",
       "                   experience_years  \\\n",
       "15                                5   \n",
       "28                               12   \n",
       "4                                 5   \n",
       "25                                8   \n",
       "22                                5   \n",
       "11                                4   \n",
       "16                          unknown   \n",
       "27  No mention of experience years.   \n",
       "26                          7 years   \n",
       "24                          Unknown   \n",
       "\n",
       "                                      education_level  \\\n",
       "15                                  Bachelor's degree   \n",
       "28                          Not mentioned in the text   \n",
       "4                                             Masters   \n",
       "25  Bachelor's degree in Computer Science or relat...   \n",
       "22                                                  A   \n",
       "11                                               None   \n",
       "16                                            unknown   \n",
       "27                                    None mentioned.   \n",
       "26                Master's degree in Computer Science   \n",
       "24                                            Unknown   \n",
       "\n",
       "                                     languages  Score  \n",
       "15                    English, Spanish, French   0.50  \n",
       "28                   Not mentioned in the text   0.50  \n",
       "4                     English, Spanish, French   0.50  \n",
       "25  English, Spanish, French, Mandarin Chinese   0.50  \n",
       "22                                     english   0.50  \n",
       "11                                       None.   0.50  \n",
       "16                                     unknown   0.25  \n",
       "27                             None mentioned.   0.25  \n",
       "26            English, German, French, Spanish   0.25  \n",
       "24                              None mentioned   0.25  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_resumes_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
