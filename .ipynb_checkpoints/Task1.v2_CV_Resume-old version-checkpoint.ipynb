{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809159d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bdfb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\apleczkan\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\apleczkan\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from langdetect import detect, DetectorFactory\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Make langdetect non-deterministic results predictable\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Instantiate the OpenAI client with your API key\n",
    "client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509d9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read PDF and extract text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3dc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into chunks with overlap\n",
    "def split_text(text, max_chunk_size, overlap_size=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for word in words:\n",
    "        if len(current_chunk) + len(word) + 1 <= max_chunk_size:\n",
    "            current_chunk += word + \" \"\n",
    "        else:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = word + \" \"\n",
    "    chunks.append(current_chunk)  # Add the last chunk\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c4be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate text using OpenAI's API (Updated for openai>=1.0.0)\n",
    "def translate_text(client, text, target_language=\"en\"):\n",
    "    response = client.create_completion(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=f\"Translate the following text to {target_language}:\\n\\n{text}\",\n",
    "        max_tokens=60  # Adjust as needed\n",
    "    )\n",
    "    # Access the text from the response\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72a8e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process all PDFs in a directory\n",
    "def process_pdfs(directory, max_chunk_size, overlap_size, output_directory):\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    translated_files_list = []\n",
    "    english_files_list = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(directory, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "            if detect(text) != 'en':\n",
    "                chunks = split_text(text, max_chunk_size, overlap_size)\n",
    "                translated_text = \"\"\n",
    "\n",
    "                for chunk in chunks:\n",
    "                    if detect(chunk) != 'en':\n",
    "                        chunk = translate_text(chunk)\n",
    "                    translated_text += chunk + \" \"\n",
    "                \n",
    "                translated_filename = f\"translated_{filename.replace('.pdf', '.txt')}\"\n",
    "                translated_path = os.path.join(output_directory, translated_filename)\n",
    "                with open(translated_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(translated_text)\n",
    "\n",
    "                translated_files_list.append(translated_filename)\n",
    "            else:\n",
    "                english_files_list.append(filename)\n",
    "\n",
    "    # Save the list of translated files\n",
    "    translated_list_filename = 'translated_files_list.txt'\n",
    "    with open(os.path.join(output_directory, translated_list_filename), 'w', encoding='utf-8') as f:\n",
    "        for file in translated_files_list:\n",
    "            f.write(f\"{file}\\n\")\n",
    "    \n",
    "    # Save the list of files that are already in English\n",
    "    english_list_filename = 'english_files_list.txt'\n",
    "    with open(os.path.join(output_directory, english_list_filename), 'w', encoding='utf-8') as f:\n",
    "        for file in english_files_list:\n",
    "            f.write(f\"{file}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c847b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\resumes_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21581aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_output_directory = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\resumes_translated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78d4581e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'Completion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m overlap_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m  \u001b[38;5;66;03m# Adjust if you need overlap between chunks\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Run the processing function\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m process_pdfs(directory, max_chunk_size, overlap_size, output_directory)\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mprocess_pdfs\u001b[1;34m(directory, max_chunk_size, overlap_size, output_directory)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m detect(chunk) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 20\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m translate_text(chunk)\n\u001b[0;32m     21\u001b[0m     translated_text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m translated_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslated_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m, in \u001b[0;36mtranslate_text\u001b[1;34m(text, target_language)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_text\u001b[39m(text, target_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      4\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-003\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m         prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslate the following text to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_language\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m  \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OpenAI' object has no attribute 'Completion'"
     ]
    }
   ],
   "source": [
    "# Set your parameters and directory paths\n",
    "directory = directory_path  # Replace with the path to your PDFs\n",
    "output_directory = translated_output_directory  # Replace with the path for the translated files\n",
    "max_chunk_size = 1000  # Adjust based on OpenAI's token limits\n",
    "overlap_size = 50  # Adjust if you need overlap between chunks\n",
    "\n",
    "# Run the processing function\n",
    "process_pdfs(directory, max_chunk_size, overlap_size, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b62822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dfcd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65ba6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba05924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
