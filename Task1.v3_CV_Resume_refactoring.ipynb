{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9cfbe7-4b5a-46c9-a464-414908206d87",
   "metadata": {},
   "source": [
    "# 1.4.1. Task 1: Working with the documents \r\n",
    "\r\n",
    "## 1. Translation.\r\n",
    "Find the resumes (or parts of them) that are not in English, and translate them into English using LLM.\r\n",
    "\r\n",
    "## 2. Entities extraction.\r\n",
    "Extract useful named entities from the resume using LLM. For example, you can extract the job title, years of experience, highest level of education, language skills, and key skills, or define any entities that you find interesting. As an additional task, you may create an Excel report that contains entities from 20-30 resumes.\r\n",
    "\r\n",
    "## 3. Summarisation.\r\n",
    "Make a short summary of the resume. You may choose any size you find useful. Defining the structure of the summary (adding the obligatory entities) or just getting it from LLM is up to you. The general idea is to provide an opportunity for recruiters to read it quickly and not scan 2-3 pages.\r\n",
    "\r\n",
    "## 4. Resume scoring.\r\n",
    "Develop a mechanism to provide a ranking of the resumes for a vacancy by providing a score (float value from 0 to 1). A particular vacancy can be found at [https://www.dataart.team/vacancies](https://www.dataart.team/vacancies) (or on LinkedIn). It should work in 2 modes: calculate the score for the provided vacancy and resume, and present the top 10 candidates for the vacancy.\r\n",
    "a and algorithms for scoring.\r\n",
    "ncy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb6f51-6804-477d-8426-af1da337c17d",
   "metadata": {},
   "source": [
    "### Installations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84b50aa-449d-41e6-903b-eb6046b93528",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pandas langdetect PyPDF2 transformers plotly matplotlib scikit-learn torch torchvision scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430f993a-2209-4021-a60f-2358e5a8a0b3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bdfb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "from langdetect import DetectorFactory, detect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d88852-7c55-4dc6-a300-eb9d1947590e",
   "metadata": {},
   "source": [
    "### Set environment variable for Open Ai client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809159d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53202e6b-24ea-418a-80e4-1b227e6cbc32",
   "metadata": {},
   "source": [
    "### Create basic Variables, paths and set Open AI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "directory_path = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\test_resumes_dataset\"\n",
    "translated_output_directory = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\resumes_translated\"\n",
    "logs_directory = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\logs\"\n",
    "max_chunk_size = 3500  \n",
    "overlap_size = 50  \n",
    "\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdaf1e0-fd25-4546-94cf-bd631dfe6169",
   "metadata": {},
   "source": [
    "### extract_text_from_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a1ca4-65ff-45f3-95ec-7de30135ed81",
   "metadata": {},
   "source": [
    "### Split text into chunks with overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3dc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, max_chunk_size, overlap_size=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for word in words:\n",
    "        if len(current_chunk) + len(word) + 1 <= max_chunk_size:\n",
    "            current_chunk += word + \" \"\n",
    "        else:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = word + \" \"\n",
    "    chunks.append(current_chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578372d7-9f7a-41fc-9578-b639c23ea7b7",
   "metadata": {},
   "source": [
    "### Function to translate text using OpenAI's API  for openai>=1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate_text(client, text, target_language=\"en\"):\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=f\"Translate the following text to {target_language}:\\n\\n{text}\",\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601bf752-6889-40dd-85f1-59fbf8e0ce94",
   "metadata": {},
   "source": [
    "### Function to process PDFs and save translated versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_pdfs(directory_path, max_chunk_size, overlap_size, translated_output_directory, client):\n",
    "    if not os.path.exists(translated_output_directory):\n",
    "        os.makedirs(translated_output_directory)\n",
    "\n",
    "    translated_files_list = []\n",
    "    english_files_list = []\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(directory_path, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "            if text.strip():\n",
    "                if detect(text) != 'en':\n",
    "                    chunks = split_text(text, max_chunk_size, overlap_size)\n",
    "                    translated_text = \"\"\n",
    "\n",
    "                    for chunk in chunks:\n",
    "                        if detect(chunk) != 'en':\n",
    "                            chunk = translate_text(client, chunk, target_language=\"en\")\n",
    "                        translated_text += chunk + \" \"\n",
    "                    \n",
    "                    # Save the translated text to a .txt file\n",
    "                    translated_filename = f\"translated_{filename.replace('.pdf', '.txt')}\"\n",
    "                    translated_path = os.path.join(translated_output_directory, translated_filename)\n",
    "                    save_text_to_file(translated_text, translated_path)\n",
    "\n",
    "                    translated_files_list.append(translated_filename)\n",
    "                else:\n",
    "                    english_files_list.append(filename)\n",
    "            else:\n",
    "                print(f\"Document {filename} is empty or contains very little text.\")\n",
    "\n",
    "    # Save the list of translated files to a text file for reference\n",
    "    save_file_list(translated_files_list, logs_directory, 'translated_files_list.txt')\n",
    "    # Optionally save the list of English files as well\n",
    "    save_file_list(english_files_list, logs_directory, 'english_files_list.txt')\n",
    "\n",
    "def save_file_list(file_list, directory, filename):\n",
    "    with open(os.path.join(directory, filename), 'w', encoding='utf-8') as f:\n",
    "        for file in file_list:\n",
    "            f.write(f\"{file}\\n\")\n",
    "\n",
    "# Function to save text to a file\n",
    "def save_text_to_file(text, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4e8ef-b432-4801-80a7-db3b4c6ae79b",
   "metadata": {},
   "source": [
    "### Create named entities to look for in resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ce8ea-f58f-444c-b133-d7ec08c5066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [\"job title\", \"years of experience\", \"highest level of education\", \"language skills\", \"key skills\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e41f2-9ec3-4c12-b528-596fdd864f71",
   "metadata": {},
   "source": [
    "### Function to extract text from TXT files with different encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f4e07-235c-4ea1-856f-4392afb44c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_txt(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'ISO-8859-1', 'cp1252']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as file:\n",
    "                return file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(f\"Cannot decode file {file_path} with any of the provided encodings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd143b-5d23-4654-94f9-d0a7cb0d7706",
   "metadata": {},
   "source": [
    "### Function to extract entities using the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dcae4f-d4f1-4962-9fe5-c5484229e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_with_llm(client, text, entities, max_chunk_size, overlap_size):\n",
    "    extracted_info = \"\"\n",
    "    chunks = split_into_chunks(text, max_chunk_size, overlap_size)  # Ensure chunks are small enough\n",
    "\n",
    "    for chunk in chunks:\n",
    "        prompt = (\n",
    "            \"Extract the following entities from this text, calculating years of experience as a decimal number where months are converted to a fractional year without any additional info: \"\n",
    "            + \", \".join(entities)\n",
    "            + \".\\n\\n\"\n",
    "            + chunk\n",
    "        )\n",
    "        prompt_length = len(prompt.split())\n",
    "\n",
    "        max_tokens_for_completion = 4097 - prompt_length\n",
    "        max_tokens_for_completion = min(max_tokens_for_completion, 300)\n",
    "\n",
    "        response = client.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens_for_completion\n",
    "        )\n",
    "        extracted_info += response.choices[0].text.strip() + \"\\n\"\n",
    "\n",
    "    return extracted_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36991005-0595-4572-9f5d-5d20daba21c0",
   "metadata": {},
   "source": [
    "### Function to process resumes and extract named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825042b0-1888-4be1-a8e0-795274758661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_resume(directory, filename, client, entities, data_list, is_txt=False):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    text = extract_text_from_txt(file_path) if is_txt else extract_text_from_pdf(file_path)\n",
    "\n",
    "    if text.strip():\n",
    "        extracted_info = extract_entities_with_llm(client, text, entities, max_chunk_size, overlap_size)\n",
    "        info_dict = {'Filename': filename}\n",
    "\n",
    "        for entity in entities:\n",
    "            pattern = re.compile(rf\"{entity}\\s*:\\s*(.*)\", re.IGNORECASE)\n",
    "            match = pattern.search(extracted_info)\n",
    "            if match:\n",
    "                info_dict[entity] = match.group(1).strip()\n",
    "            else:\n",
    "                info_dict[entity] = None\n",
    "\n",
    "        data_list.append(info_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a0429b-fcf9-43ac-b053-98ea3c74e6b2",
   "metadata": {},
   "source": [
    "### Function to create a report of named entities from resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162738f-0d91-4bd0-ba4f-c05d60b29733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_entities_report(directory_path, translated_output_directory, client, entities):\n",
    "    data = []\n",
    "\n",
    "    # Process PDFs in the original directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            process_resume(directory_path, filename, client, entities, data)\n",
    "\n",
    "    # Process translated PDFs in the output directory\n",
    "    for filename in os.listdir(translated_output_directory):\n",
    "        if filename.lower().startswith('translated_') and filename.lower().endswith('.txt'):\n",
    "            process_resume(translated_output_directory, filename, client, entities, data, is_txt=True)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(os.path.join(logs_directory, 'resume_entities_report.xlsx'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7919cbeb-4d82-49d3-a4d5-2ce1e51b85db",
   "metadata": {},
   "source": [
    "### Load the DataFrame from the Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80cae43-9660-42a3-8a71-8fc4feef2974",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(translated_output_directory, 'resume_entities_report.xlsx')\n",
    "df = pd.read_excel(file_path)\n",
    "df.set_index('Filename', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Extract 'years of experience' data from the DataFrame\n",
    "years_of_experience = df['years of experience']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdec9855-0a73-4c4f-8ef7-eb6c86b98342",
   "metadata": {},
   "source": [
    "### Function to calculate numeric years of experience from text descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9e913-5c27-4146-9c56-99ffa5d2a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_years_of_experience(client, text_descriptions):\n",
    "    numeric_experience_list = []\n",
    "\n",
    "    for text in text_descriptions:\n",
    "        prompt = f\"Convert the following description of work experience '{text}' into a numeric value representing total years of experience.\"\n",
    "\n",
    "        response = client.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=50,\n",
    "            temperature=0.5\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # Find all numeric values in the response and take the first one\n",
    "            # This regex matches numbers with optional decimal points\n",
    "            extracted_numbers = re.findall(r'\\b\\d+\\.?\\d*\\b', response.choices[0].text.strip())\n",
    "            if extracted_numbers:\n",
    "                # Convert the first extracted number to a float\n",
    "                numeric_experience = float(extracted_numbers[0])\n",
    "                numeric_experience_list.append(numeric_experience)\n",
    "            else:\n",
    "                # If no numbers are found, it may not be possible to calculate experience\n",
    "                numeric_experience_list.append(float('nan'))  # Append NaN for manual review\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            numeric_experience_list.append(float('nan'))  # Append NaN for manual review\n",
    "\n",
    "    return numeric_experience_list\n",
    "\n",
    "# Assuming you have set up the 'client' and have the 'years_of_experience' from the DataFrame\n",
    "text_descriptions = df['years of experience'].astype(str).tolist()\n",
    "numeric_years_of_experience = calculate_years_of_experience(client, text_descriptions)\n",
    "\n",
    "# Add the numeric years of experience back to the DataFrame\n",
    "df['numeric_years_of_experience'] = numeric_years_of_experience\n",
    "\n",
    "# Output confirmation\n",
    "print(f\"The updated DataFrame has been saved to {new_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba32378-9b06-4c95-9ee2-281b1f192332",
   "metadata": {},
   "source": [
    "### Function to summarize resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dfcd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize resumes using OpenAI's GPT-3 model\n",
    "def summarize_text(client, text, max_chunk_size=3000, overlap_size=50):\n",
    "    chunks = split_text(text, max_chunk_size, overlap_size)\n",
    "    summary = \"\"\n",
    "\n",
    "    for chunk in chunks:\n",
    "        prompt = (\n",
    "            \"Please summarize the following resume into a short paragraph that includes \"\n",
    "            \"the job title, years of experience, highest level of education, language skills, \"\n",
    "            \"and key skills:\\n\\n\" + chunk\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = client.completions.create(\n",
    "                model=\"gpt-3.5-turbo-instruct\",\n",
    "                prompt=prompt,\n",
    "                max_tokens=150,  # Adjust as needed for the summary length\n",
    "                temperature=0.5\n",
    "            )\n",
    "            chunk_summary = response.choices[0].text.strip()\n",
    "            summary += chunk_summary + \"\\n\"\n",
    "        except Exception as e:\n",
    "            # Handle any exception that occurs\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e732f0-db46-41aa-a2d2-92a13692d183",
   "metadata": {},
   "source": [
    "### Process and Summarize Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727019f-b667-445f-89b7-12cb2b5739f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and summarize resumes, assuming summarize_text function is defined\n",
    "for filename in df.index:\n",
    "    # Determine the correct file path\n",
    "    if filename.startswith('translated_'):\n",
    "        resume_path = os.path.join(translated_output_directory, filename)\n",
    "    else:\n",
    "        resume_path = os.path.join(directory_path, filename)\n",
    "\n",
    "    # Skip non-resume files like 'translated_files_list.txt'\n",
    "    if 'translated_files_list' in filename:\n",
    "        continue\n",
    "\n",
    "    # Check the file extension and read the content\n",
    "    if resume_path.lower().endswith('.pdf'):\n",
    "        try:\n",
    "            resume_text = extract_text_from_pdf(resume_path)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while reading PDF file: {e}\")\n",
    "            continue\n",
    "    elif resume_path.lower().endswith('.txt'):\n",
    "        try:\n",
    "            resume_text = extract_text_from_txt(resume_path)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while reading text file: {e}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"Unsupported file format for file: {resume_path}\")\n",
    "        continue\n",
    "\n",
    "    # Generate a summary for the resume (assuming summarize_text function is defined)\n",
    "    summary = summarize_text(client, resume_text)\n",
    "    df.at[filename, 'Summary'] = summary\n",
    "\n",
    "# Uncomment the below lines to see the DataFrame and save it\n",
    "print(df.head())\n",
    "df.to_excel(os.path.join(logs_directory, 'updated_resume_summaries.xlsx'))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe489854-05af-4012-ab60-43aa42ca201e",
   "metadata": {},
   "source": [
    "### Scoring criteria based on provided vacancy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52d4721-b9da-4130-a26b-54597cc23b95",
   "metadata": {},
   "source": [
    "### Job requirements from job description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c70af-8248-4c50-9f36-0a2b24928eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"\n",
    "FullStack(NodeJS, ReactJS), Online Genealogy Service\n",
    "Client\n",
    "The client is an international company that provides an online genealogy service that helps its clients understand their past and family history.\n",
    "\n",
    "Project overview\n",
    "The core programming language is JavaScript (ES2020), a website running on React.js and GraphQL and the back-end platform is based on Node.js (Express). Microservices running under Kubernetes. The project methodology is Scrum.\n",
    "\n",
    "Team\n",
    "There are a few Full Stack teams, up to 8 people each. Each team has a team lead and a product owner.\n",
    "\n",
    "Position overview\n",
    "We are looking for a specialist to join one of the teams (which is more Frontend oriented) is working on the further development of existing platforms. Regarding the work schedule, each employee should be available till 4 pm UK time.\n",
    "\n",
    "Technology stack\n",
    "JavaScript, React.js, GraphQL, Node.js (Express), Kubernetes.\n",
    " \n",
    "Requirements\n",
    "Development experience using a Node.js (Express) + React.js stack\n",
    "Experience with SQL Server\n",
    "Experience with PostgreSQL\n",
    "Knowledge of Kafka\n",
    "Knowledge of RabbitMQ\n",
    "Dev-level experience with K8s/Docker\n",
    "Knowledge of sound engineering practices like pair programming, upfront automated testing, continuous deployment, and trunk-based development\n",
    "Spoken English\n",
    "\n",
    "Nice to have\n",
    "Knowledge of Apollo engine, Kafka, Postgres\n",
    "Experience with microservices architecture development\n",
    "Experience with GraphQL\n",
    "Experience with RabbitMQ, SQL Server\n",
    "Experience in development with C#\n",
    "Experience with SOLR\n",
    "Software development experience in Python\n",
    "\"\"\"\n",
    "\n",
    "entities = [\n",
    "    \"job title\", \"years of experience\", \"highest level of education\", \"language skills\", \"key skills\"\n",
    "]\n",
    "\n",
    "\n",
    "prompt = (\n",
    "    \"Please structure the job requirements from the following text into a JSON-like format with these categories: \"\n",
    "    + \", \".join(entities)\n",
    "    + \".\\n\\n\"\n",
    "    + job_description\n",
    ")\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=300  # Adjust as needed\n",
    ")\n",
    "extracted_requirements = response.choices[0].text.strip()\n",
    "print(extracted_requirements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda67ef2-9846-400f-a4a0-135ae065c025",
   "metadata": {},
   "source": [
    "### Scoring function - this solution was not giving very well results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15ac27-f999-4499-b0f0-6f2a701718ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fuzzywuzzy python-Levenshtein\n",
    "# import os\n",
    "# import re\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# from collections import Counter\n",
    "# from fuzzywuzzy import fuzz  # For fuzzy string matching\n",
    "\n",
    "# max_chunk_size = 3000  \n",
    "# overlap_size = 50    \n",
    "# directory_path = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\test_resumes_dataset\"\n",
    "# translated_output_directory = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\resumes_translated\"\n",
    "\n",
    "# entities = [\"job title\", \"years of experience\", \"highest level of education\", \"language skills\", \"key skills\"]\n",
    "\n",
    "# # Define the job description as a string\n",
    "# job_description_str = \"\"\"\n",
    "# {\n",
    "#     \"job title\": \"FullStack Developer\",\n",
    "#     \"years of experience\": \"At least 2 years of development experience\",\n",
    "#     \"highest level of education\": \"Bachelor's or higher in Computer Science or related field\",\n",
    "#     \"language skills\": \"Fluent in spoken English\",\n",
    "#     \"key skills\": [\n",
    "#         \"Node.js\", \"React.js\", \"GraphQL\", \"Kubernetes\", \"SQL Server\",\n",
    "#         \"PostgreSQL\", \"Kafka\", \"RabbitMQ\", \"C#\", \"SOLR\", \"Python\",\n",
    "#         \"Sound engineering practices\", \"Pair programming\",\n",
    "#         \"Automated testing\", \"Continuous deployment\", \"Trunk-based development\"\n",
    "#     ]\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "# # The `job_description` variable should be a dictionary parsed from JSON.\n",
    "# job_description = json.loads(job_description_str)\n",
    "\n",
    "# def split_into_chunks(text, max_chunk_size, overlap_size):\n",
    "#     words = text.split()\n",
    "#     chunks = []\n",
    "#     current_chunk = []\n",
    "\n",
    "#     for word in words:\n",
    "#         current_chunk.append(word)\n",
    "#         if len(' '.join(current_chunk)) > max_chunk_size:\n",
    "#             # Split the chunk at the max chunk size\n",
    "#             chunk = ' '.join(current_chunk[:len(current_chunk)-overlap_size])\n",
    "#             chunks.append(chunk)\n",
    "#             # Start the next chunk with the overlap\n",
    "#             current_chunk = current_chunk[-overlap_size:]\n",
    "    \n",
    "#     # Add the last chunk\n",
    "#     chunks.append(' '.join(current_chunk))\n",
    "#     return chunks\n",
    "\n",
    "# def extract_entities_with_llm(client, text, entities, max_chunk_size, overlap_size):\n",
    "#     extracted_info = {entity: [] for entity in entities}  # Initialize as a dictionary\n",
    "#     chunks = split_into_chunks(text, max_chunk_size, overlap_size)  # Ensure chunks are small enough\n",
    "\n",
    "#     for chunk in chunks:\n",
    "#         prompt = f\"Please extract the following entities from this text: {', '.join(entities)}.\\n\\n{chunk}\"\n",
    "#         prompt_length = len(prompt.split())  # Calculate the prompt length in tokens\n",
    "\n",
    "#         max_tokens_for_completion = 4097 - prompt_length  # Adjust max tokens based on prompt length\n",
    "#         max_tokens_for_completion = min(max_tokens_for_completion, 300)  # Limit to 300 or less\n",
    "\n",
    "#         response = client.completions.create(\n",
    "#             model=\"gpt-3.5-turbo-instruct\",\n",
    "#             prompt=prompt,\n",
    "#             max_tokens=max_tokens_for_completion\n",
    "#         )\n",
    "\n",
    "#         # Process the structured response and fill the extracted_info dict\n",
    "#         structured_response = response.choices[0].text.strip().split('\\n')\n",
    "#         for line in structured_response:\n",
    "#             for entity in entities:\n",
    "#                 if line.lower().startswith(entity.lower() + ':'):\n",
    "#                     split_line = line.split(':', 1)\n",
    "#                     if len(split_line) > 1:\n",
    "#                         value = split_line[1].strip()\n",
    "#                         if value:\n",
    "#                             if entity == 'key skills':  # Special case as we expect a list\n",
    "#                                 skills = re.findall(r\"[\\w']+\", value)\n",
    "#                                 extracted_info[entity].extend(skills)\n",
    "#                             else:\n",
    "#                                 extracted_info[entity].append(value)\n",
    "#                     break  # Move on to the next line once the entity is found\n",
    "\n",
    "#     # Aggregate the extracted information by combining or choosing the most mentioned entity\n",
    "#     for entity, values in extracted_info.items():\n",
    "#         if values:\n",
    "#             if entity == 'key skills':\n",
    "#                 skills_counter = Counter(values)\n",
    "#                 # Select skills that are most frequently mentioned\n",
    "#                 extracted_info[entity] = [skill for skill, count in skills_counter.items() if count > 1]  # Adjusted to filter skills mentioned more than once\n",
    "#             else:\n",
    "#                 # For other entities, we expect a single value, so we take the most frequent one\n",
    "#                 value_counter = Counter(values)\n",
    "#                 extracted_info[entity], _ = value_counter.most_common(1)[0]\n",
    "\n",
    "#     # Now, the extracted_info is ready for scoring against the job_description\n",
    "#     return extracted_info\n",
    "\n",
    "\n",
    "\n",
    "# def extract_text_from_txt(file_path):\n",
    "#     encodings = ['utf-8', 'latin1', 'ISO-8859-1', 'cp1252']  # Common encodings\n",
    "#     for encoding in encodings:\n",
    "#         try:\n",
    "#             with open(file_path, 'r', encoding=encoding) as file:\n",
    "#                 return file.read()\n",
    "#         except UnicodeDecodeError:\n",
    "#             continue\n",
    "#     raise ValueError(f\"Cannot decode file {file_path} with any of the provided encodings.\")\n",
    "\n",
    "# # We keep the existing functions extract_text_from_txt, extract_text_from_pdf, and split_into_chunks unchanged.\n",
    "# # ...\n",
    "\n",
    "# def score_resume(extracted_info, job_description):\n",
    "#     score = 0\n",
    "#     total_weight = 0\n",
    "\n",
    "#     # Define weights for each entity\n",
    "#     weights = {\n",
    "#         \"job title\": 2,\n",
    "#         \"years of experience\": 1.5,\n",
    "#         \"highest level of education\": 1,\n",
    "#         \"language skills\": 1,\n",
    "#         \"key skills\": 3\n",
    "#     }\n",
    "\n",
    "#     def get_first_value(entity):\n",
    "#         return ' '.join(extracted_info[entity]).lower() if entity in extracted_info and extracted_info[entity] else ''\n",
    "\n",
    "#     # Function to calculate and weight individual scores\n",
    "#     def calculate_weighted_score(entity, extracted_value, required_value):\n",
    "#         if entity == \"key skills\":\n",
    "#             total_skills = len(required_value)\n",
    "#             matching_skills = sum(skill in extracted_value for skill in required_value)\n",
    "#             return (matching_skills / total_skills) * weights[entity]\n",
    "#         else:\n",
    "#             return (1 if fuzz.partial_ratio(extracted_value, required_value) > 80 else 0) * weights[entity]\n",
    "\n",
    "#     # Scoring for Years of Experience\n",
    "#     extracted_years_list = re.findall(r\"\\d+\", get_first_value('years of experience'))\n",
    "#     required_years = float(re.findall(r\"\\d+\", job_description['years of experience'])[0])\n",
    "#     extracted_years = float(extracted_years_list[0]) if extracted_years_list else 0\n",
    "#     experience_score = min(extracted_years / required_years, 1) * weights['years of experience']\n",
    "#     score += experience_score\n",
    "\n",
    "#     # Scoring for other entities\n",
    "#     for entity in ['job title', 'highest level of education', 'language skills']:\n",
    "#         extracted_value = get_first_value(entity)\n",
    "#         required_value = job_description[entity].lower()\n",
    "#         score += calculate_weighted_score(entity, extracted_value, required_value)\n",
    "\n",
    "#     # Special handling for 'key skills' as it's a list\n",
    "#     if 'key skills' in extracted_info:\n",
    "#         score += calculate_weighted_score('key skills', extracted_info['key skills'], job_description['key skills'])\n",
    "\n",
    "#     total_weight = sum(weights.values())\n",
    "#     return score / total_weight  # Normalize score based on total weight\n",
    "\n",
    "\n",
    "# def extract_and_score_resume(client, text, job_description, entities, max_chunk_size, overlap_size):\n",
    "#     extracted_entities = extract_entities_with_llm(client, text, entities, max_chunk_size, overlap_size)\n",
    "    \n",
    "#     # info_dict to collect each entity's most common or first occurrence in the resume\n",
    "#     info_dict = {entity: [] for entity in entities}  # Initialize with empty lists\n",
    "\n",
    "#     for entity in entities:\n",
    "#         # Directly access the entity's value from the extracted_entities dictionary\n",
    "#         if entity in extracted_entities and extracted_entities[entity]:\n",
    "#             info_dict[entity] = extracted_entities[entity]\n",
    "\n",
    "#     # Now you can score the resume based on the content of info_dict and the job_description\n",
    "#     resume_score = score_resume(info_dict, job_description)\n",
    "#     return info_dict, resume_score\n",
    "\n",
    "# def create_entities_report(\n",
    "#     directory_path=directory_path,\n",
    "#     translated_output_directory=translated_output_directory,\n",
    "#     client=client,\n",
    "#     job_description=job_description,\n",
    "#     entities=entities,\n",
    "#     max_chunk_size=max_chunk_size,\n",
    "#     overlap_size=overlap_size\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     This function processes all resumes in the given directories, extracting entities and scoring them against a job description.\n",
    "#     It generates a report that ranks the resumes based on their scores.\n",
    "\n",
    "#     :param directory_path: Path to the directory containing the original resumes.\n",
    "#     :param translated_output_directory: Path to the directory where the translated resumes are stored.\n",
    "#     :param client: OpenAI client initialized with an API key.\n",
    "#     :param job_description: Dictionary containing the job description to score against.\n",
    "#     :param entities: List of entity types to extract from the resumes.\n",
    "#     :param max_chunk_size: Maximum size of the text chunk to be processed by the LLM in a single request.\n",
    "#     :param overlap_size:Size of the overlap between chunks of text to ensure continuity is maintained in entity extraction.\n",
    "#     \"\"\"\n",
    "#     data = []\n",
    "    \n",
    "#     # Process all resumes in the directories\n",
    "#     for directory, is_txt in [(directory_path, False), (translated_output_directory, True)]:\n",
    "#         for filename in os.listdir(directory):\n",
    "#             file_extension = '.txt' if is_txt else '.pdf'\n",
    "#             if filename.lower().endswith(file_extension):\n",
    "#                 file_path = os.path.join(directory, filename)\n",
    "                \n",
    "#                 if is_txt:\n",
    "#                     text = extract_text_from_txt(file_path)\n",
    "#                 else:\n",
    "#                     text = extract_text_from_pdf(file_path)\n",
    "\n",
    "#                 if text.strip():\n",
    "#                     # Assuming that extract_and_score_resume is a function defined elsewhere \n",
    "#                     # that takes the following arguments in the order given below.\n",
    "#                     info_dict, resume_score = extract_and_score_resume(client, text, job_description, entities, max_chunk_size, overlap_size)\n",
    "#                     info_dict['Filename'] = filename\n",
    "#                     info_dict['Score'] = resume_score\n",
    "#                     data.append(info_dict)\n",
    "\n",
    "#     # Creating a DataFrame from the extracted data and scores\n",
    "#     df = pd.DataFrame(data)\n",
    "#     df = df.sort_values(by='Score', ascending=False)  # Sort dataframe by score in descending order\n",
    "#     output_file_path = os.path.join(logs_directory, 'resume_scoring_report.xlsx')\n",
    "#     df.to_excel(output_file_path, index=False)\n",
    "\n",
    "#     print(f\"Report generated and saved to {output_file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# # Call the main function with the correct parameters.\n",
    "# create_entities_report(\n",
    "#     directory_path=directory_path,\n",
    "#     translated_output_directory=translated_output_directory,\n",
    "#     client=client,\n",
    "#     job_description=job_description,\n",
    "#     entities=entities,\n",
    "#     max_chunk_size=max_chunk_size,\n",
    "#     overlap_size=overlap_size\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb0f12-c7ab-4fe3-a23b-566b111bfb79",
   "metadata": {},
   "source": [
    "### Because previous solution was not giving appropriate scoring mechanism I switched to embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c81914-dcb6-46c6-b92a-4f7b8d3a23cb",
   "metadata": {},
   "source": [
    "### Using embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0534b-d224-42c4-9faa-083597a851fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths for the Excel files\n",
    "excel_file_1 = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\logs\\\\updated_resume_summaries.xlsx\"\n",
    "excel_file_2 = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\logs\\\\updated_years_resume_entities_report.xlsx\"\n",
    "\n",
    "# Load the Excel files into DataFrames\n",
    "df1 = pd.read_excel(excel_file_1)\n",
    "df2 = pd.read_excel(excel_file_2)\n",
    "\n",
    "# Ensure that \"Filename\" is set as the index for both DataFrames to use for alignment\n",
    "df1.set_index('Filename', inplace=True)\n",
    "df2.set_index('Filename', inplace=True)\n",
    "\n",
    "# Replace the \"ABC\" column in df1 with the \"DEF\" column from df2\n",
    "df1['years of experience'] = df2['numeric_years_of_experience']\n",
    "\n",
    "# Reset the index if you want \"Filename\" back as a column\n",
    "df1.reset_index(inplace=True)\n",
    "\n",
    "# Define the complete path for saving the modified DataFrame to a new Excel file\n",
    "save_path = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\logs\\\\updated_years_of_exp_and_summary.xlsx\"\n",
    "\n",
    "# Save the modified DataFrame back to an Excel file with the specified path\n",
    "df1.to_excel(save_path, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994529b8-7b41-423f-9a76-9f3a9b429f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(20)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc891e45-cd88-4241-a314-57302b328ba0",
   "metadata": {},
   "source": [
    "### working embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10986e30-346c-44df-88e5-5683035e6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set up the OpenAI client with your API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    # Access the embedding using dot notation\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Define the path to your Excel file\n",
    "excel_file_path = \"C:/Users/apleczkan/PycharmProjects/task1-cv-resumes/logs/updated_years_of_exp_and_summary.xlsx\"\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file_path, index_col='Filename')\n",
    "\n",
    "# Define which columns contain text that you want to embed\n",
    "text_columns = ['job title', 'years of experience', 'highest level of education', 'language skills', 'key skills', 'Summary']\n",
    "\n",
    "# Generate embeddings for the specified text columns\n",
    "for column in text_columns:\n",
    "    # Skip columns with non-text data\n",
    "    if df[column].dtype == 'object':\n",
    "        # Use the get_embedding function directly\n",
    "        df[column + ' embedding'] = df[column].apply(lambda x: get_embedding(x) if pd.notnull(x) else np.nan)\n",
    "\n",
    "# Save the DataFrame, including the embeddings, back to an Excel file\n",
    "save_path = \"C:/Users/apleczkan/PycharmProjects/task1-cv-resumes/logs/updated_with_embeddings.xlsx\"\n",
    "df.to_excel(save_path, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257841b-9833-445b-9fa7-af5c73ab9164",
   "metadata": {},
   "source": [
    "### Read file as xlsx and save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f544d8f4-d498-47db-9327-7e32f6dfb267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set up the OpenAI client with your API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# Embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "\n",
    "def get_embedding(text, model=embedding_model):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    # Access the embedding using dot notation\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Define the path to your Excel file\n",
    "excel_file_path = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\logs\\\\updated_years_of_exp_and_summary.xlsx\"  # Update this path\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file_path, index_col='Filename')\n",
    "\n",
    "# Define which columns contain text that you want to embed\n",
    "text_columns = ['job title', 'years of experience', 'highest level of education', 'language skills', 'key skills', 'Summary']\n",
    "\n",
    "# Generate embeddings for the specified text columns\n",
    "for column in text_columns:\n",
    "    # Skip columns with non-text data\n",
    "    if df[column].dtype == 'object':\n",
    "        # Use the get_embedding function directly\n",
    "        df[column + ' embedding'] = df[column].apply(lambda x: get_embedding(x) if pd.notnull(x) else np.nan)\n",
    "\n",
    "# Save the DataFrame, including the embeddings, back to a CSV file\n",
    "save_path = \"C:/Users/apleczkan/PycharmProjects/task1-cv-resumes/logs/updated_with_embeddings.csv\"  # Update this path\n",
    "df.to_csv(save_path, index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3bcc8b-7ad3-49b0-8da9-a1bdd7f9f099",
   "metadata": {},
   "source": [
    "### Check if everything worked as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd5b77-40f1-4afa-9e4b-d3acd6d90ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/apleczkan/PycharmProjects/task1-cv-resumes/logs/updated_with_embeddings.csv\")\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198188f-95a6-47ce-a2c9-94cdd0803917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from ast import literal_eval\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Function to get embedding\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# Function to convert string representation of a list to an actual list of floats\n",
    "# Custom function to convert string representation of a list to an actual list of floats\n",
    "def string_to_float_list(s):\n",
    "    try:\n",
    "        return np.array(literal_eval(s))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Function to check if a string can be evaluated to a list\n",
    "def can_convert_to_list(s):\n",
    "    try:\n",
    "        _ = eval(s)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Set up the OpenAI client with your API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Define a utility function for cosine similarity\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "# Break down the job description\n",
    "job_description = {\n",
    "    \"job title\": \"FullStack Developer\",\n",
    "    \"years of experience\": \"At least 2 years of development experience\",\n",
    "    \"highest level of education\": \"Bachelor's or higher in Computer Science or related field\",\n",
    "    \"language skills\": \"Fluent in spoken English\",\n",
    "    \"key skills\": \"Node.js, React.js, GraphQL, Kubernetes, SQL Server, \"\n",
    "                 \"PostgreSQL, Kafka, RabbitMQ, C#, SOLR, Python, \"\n",
    "                 \"Sound engineering practices, Pair programming, \"\n",
    "                 \"Automated testing, Continuous deployment, Trunk-based development\"\n",
    "}\n",
    "\n",
    "job_description_embeddings = {}\n",
    "for key, value in job_description.items():\n",
    "    job_description_embeddings[key] = get_embedding(value)\n",
    "\n",
    "\n",
    "\n",
    "# Embed the job description\n",
    "job_description_embedding = get_embedding(job_description_str)\n",
    "\n",
    "# Load the DataFrame with embeddings from a CSV file\n",
    "df_path = \"C:/Users/apleczkan/PycharmProjects/task1-cv-resumes/logs/updated_with_embeddings.csv\"\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# Convert string representations of lists back into actual lists\n",
    "embedding_columns = [col for col in df.columns if 'embedding' in col]\n",
    "for column in embedding_columns:\n",
    "    df[column] = df[column].apply(string_to_float_list)\n",
    "\n",
    "# Drop rows with NaN values in embedding columns after conversion\n",
    "df.dropna(subset=embedding_columns, inplace=True)\n",
    "\n",
    "# Define which columns contain embeddings that you want to compare\n",
    "resume_embedding_columns = [\n",
    "    'job title embedding',\n",
    "    'years of experience embedding',\n",
    "    'highest level of education embedding',\n",
    "    'language skills embedding',\n",
    "    'key skills embedding',\n",
    "    'Summary embedding'\n",
    "]\n",
    "\n",
    "def search_resumes(df):\n",
    "    similarities = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Compute similarity for each aspect of the job description\n",
    "        similarity_scores = []\n",
    "        for key in job_description_embeddings.keys():\n",
    "            resume_embedding = row.get(f'{key} embedding')\n",
    "            if isinstance(resume_embedding, np.ndarray):\n",
    "                job_embedding = job_description_embeddings[key]\n",
    "                similarity = cosine_similarity(resume_embedding, job_embedding)\n",
    "                similarity_scores.append(similarity)\n",
    "\n",
    "        # Average the similarity scores if there are valid scores\n",
    "        if similarity_scores:\n",
    "            avg_similarity = np.nanmean(similarity_scores)\n",
    "            similarities.append((row['Filename'], avg_similarity))\n",
    "\n",
    "    similarity_df = pd.DataFrame(similarities, columns=['Filename', 'similarity'])\n",
    "    \n",
    "    csv_file_path = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\logs\\\\scores.csv\"\n",
    "    similarity_df.to_csv(csv_file_path, index=True)\n",
    "    print(f'DataFrame saved to {csv_file_path}')\n",
    "\n",
    "\n",
    "    return similarity_df.sort_values('similarity', ascending=False)\n",
    "\n",
    "\n",
    "def average_embedding(row):\n",
    "    embeddings = [row[col] for col in resume_embedding_columns if isinstance(row[col], np.ndarray)]\n",
    "    if embeddings:\n",
    "        return np.mean(np.stack(embeddings), axis=0)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "top_matches = search_resumes(df)\n",
    "\n",
    "print(top_matches.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7749e-d3d6-420e-ae76-ea283c15de3a",
   "metadata": {},
   "source": [
    "### Combine scores with existing excel file and save under new name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c161bf32-151e-4ec2-9f72-a163a39ce952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file paths\n",
    "excel_file = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\logs\\\\updated_years_of_exp_and_summary.xlsx\"\n",
    "csv_file_path = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\logs\\\\scores.csv\"\n",
    "output_excel_file = \"C:\\\\Users\\\\apleczkan\\\\PycharmProjects\\\\task1-cv-resumes\\\\logs\\\\resumes_summary_scores_sorted.xlsx\"\n",
    "\n",
    "excel_df = pd.read_excel(excel_file)\n",
    "scores_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "scores_df = scores_df.rename(columns={'similarity': 'scores'})\n",
    "excel_df['scores'] = scores_df['scores']\n",
    "\n",
    "# Sort the combined DataFrame by the 'scores' column\n",
    "sorted_df = excel_df.sort_values(by='scores', ascending=False)\n",
    "sorted_df = sorted_df.drop(columns=[\"Unnamed: 0\"])\n",
    "sorted_df = sorted_df.set_index(\"Filename\")\n",
    "sorted_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"Sorted and saved DataFrame to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e32d7584-260e-410d-ae11-ad6d3d5f12ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted DataFrame:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sorted_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorted DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m sorted_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sorted_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Sorted DataFrame:\")\n",
    "sorted_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
